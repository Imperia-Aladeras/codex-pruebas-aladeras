{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f69091",
   "metadata": {},
   "source": [
    "# PIPLEINE VERSIÓN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc56d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Feature Engineering Genérico ---\n",
    "def make_features(df_long, cluster_df, lags = [1, 3, 6, 12]):\n",
    "    df = df_long.copy().merge(cluster_df, on = 'product_code')\n",
    "    df = df.sort_values(['product_code', 'date'])\n",
    "\n",
    "    # lags y rolling means\n",
    "    for k in lags:\n",
    "        df[f'lag_{k}'] = df.groupby('product_code')['demand'].shift(k)\n",
    "        df[f'rollmean_{k}'] = df.groupby('product_code')['demand'].transform(lambda x: x.shift(1).rolling(k).mean())\n",
    "\n",
    "    # dummy mes\n",
    "    df_feat = make_features(df_long, cluster_df)\n",
    "    \n",
    "    # lista de columnas de entrada\n",
    "    feature_cols = [c for c in df_feat.columns \n",
    "                    if c.startswith('lag_') \n",
    "                    or c.startswith('rollmean_') \n",
    "                    or c.startswith('month_') \n",
    "                    or c == 'cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e758e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) LightGBM Puro ---\n",
    "X = df_feat[feature_cols]\n",
    "y = df_feat['demand']\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0, shuffle = True)\n",
    "\n",
    "reg_pure = lgb.LGBMRegressor(n_estimators = 500, random_state = 0)\n",
    "reg_pure.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef25ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación rápida\n",
    "y_pred = reg_pure.predict(X_val)\n",
    "print('LightGBM Puro - MAE:', mean_absolute_error(y_val, y_pred), 'RMSE:', np.sqrt(mean_squared_error(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886a7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) LightGBM Two-Stage ---\n",
    "# Clasificador\n",
    "f = df_feat['flag']\n",
    "X_trf, X_valf, f_tr, f_val = train_test_split(X, f, test_size = 0.2, random_state = 0, shuffle = True)\n",
    "clf = lgb.LGBMClassifier(n_estimators = 200, random_state = 0)\n",
    "clf.fit(X_trf, f_tr)\n",
    "print('LightGBM Two-Stage - Clasif Precision:', clf.score(X_valf, f_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a784d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresor Sobre casos positivos (y > 0)\n",
    "mask = f_tr == 1\n",
    "reg2 = lgb.LGBMRegressor(n_estimators = 500, random_state = 0)\n",
    "reg2.fit(X_trf[mask], df_feat.loc[X_trf.index[mask], 'demand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0439cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar Fase Completa\n",
    "X_test = X_val.copy()\n",
    "flags = clf.predict(X_test)\n",
    "yhat2 = np.where(flags == 1, reg2.predict(X_test), 0.0)\n",
    "print('LightGBM Two-Stage - MAE:', mean_absolute_error(y_val, yhat2), 'RMSE:', np.sqrt(mean_squared_error(y_val, yhat2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ed26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4) Wrappers para backtest_long ---\n",
    "def lgbm_pure_wrapper(series, alpha=None, h=3, **kw):\n",
    "    # construye features a partir de la serie y kw['cluster']\n",
    "    import pandas as _pd\n",
    "    hist = list(series)\n",
    "    feats = {}\n",
    "    for k in [1,3,6,12]:\n",
    "        feats[f'lag_{k}'] = hist[-k] if len(hist)>=k else 0.0\n",
    "        feats[f'rollmean_{k}'] = (sum(hist[-k-1:-1])/k) if len(hist)>k else 0.0\n",
    "    # mes y cluster estáticos\n",
    "    for d in range(2,13):\n",
    "        feats[f'month_{d}'] = 0\n",
    "    feats['cluster'] = kw.get('cluster',0)\n",
    "    Xp = _pd.DataFrame([feats])\n",
    "    return reg_pure.predict(Xp).repeat(h)\n",
    "\n",
    "def lgbm_2phase_wrapper(series, alpha=None, h=3, **kw):\n",
    "    import pandas as _pd\n",
    "    hist = list(series)\n",
    "    preds = []\n",
    "    for t in range(h):\n",
    "        feats = {}\n",
    "        for k in [1,3,6,12]:\n",
    "            feats[f'lag_{k}'] = hist[-k] if len(hist)>=k else 0.0\n",
    "            feats[f'rollmean_{k}'] = (sum(hist[-k-1:-1])/k) if len(hist)>k else 0.0\n",
    "        for d in range(2,13):\n",
    "            feats[f'month_{d}'] = 0\n",
    "        feats['cluster'] = kw.get('cluster',0)\n",
    "        Xp = _pd.DataFrame([feats])\n",
    "        flag = clf.predict(Xp)[0]\n",
    "        yhat = reg2.predict(Xp)[0] if flag==1 else 0.0\n",
    "        preds.append(yhat)\n",
    "        hist.append(yhat)\n",
    "    return np.array(preds)\n",
    "\n",
    "# --- 5) Evaluación cluster-aware backtest ---\n",
    "methods_ext = [\n",
    "    ('Croston', croston_forecast),\n",
    "    ('SBA',     sba_forecast),\n",
    "    ('SBJ',     sbj_forecast),\n",
    "    ('TSB',     tsb_wrapper),\n",
    "    ('GBM-puro', lgbm_pure_wrapper),\n",
    "    ('GBM-2fases', lgbm_2phase_wrapper)\n",
    "]\n",
    "\n",
    "frames = []\n",
    "for name, func in methods_ext:\n",
    "    res = backtest_long(df_long, func, h=3, alpha=0.1,\n",
    "                        cluster=None)  # backtest_long ignora alpha para lgb wrappers\n",
    "    res['model'] = name\n",
    "    frames.append(res)\n",
    "\n",
    "df_compare = pd.concat(frames, ignore_index=True)\n",
    "print(df_compare.groupby('model')[['MAE','MAPE','RMSE']].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a76403",
   "metadata": {},
   "source": [
    "Con esto cubrimos la fase 1:\n",
    "\n",
    "Montamos un GBM puro y un GBM dos-fases.\n",
    "\n",
    "Los validamos rápidamente contra un split de hold-out para verificar que funcionan.\n",
    "\n",
    "Creamos los wrappers que permiten integrarlos en tu pipeline de backtest cluster-aware.\n",
    "\n",
    "Ejecutamos backtest_long para comparar MAE/MAPE/RMSE contra Croston/SBA/SBJ/TSB.\n",
    "\n",
    "Cuando lo ejecutes, revisa la tabla final y las distribuciones de error. A partir de ahí decidimos si afinamos parámetros o pasamos a la siguiente fase (LSTM/GRU)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
